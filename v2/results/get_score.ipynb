{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from galileo.experiments import get_experiment, get_experiments\n",
    "from galileo.projects import get_project\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"gpt-4.1-nano-2025-04-14\"\n",
    "\n",
    "project_id = get_project(name=project_name).id\n",
    "# experiment = get_experiment(project_id=project_id, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-mini-2025-04-14-banking-extreme_scenario_recovery\n",
      "gpt-4.1-mini-2025-04-14-banking-empathetic_resolution\n",
      "gpt-4.1-mini-2025-04-14-banking-scope_management\n",
      "gpt-4.1-mini-2025-04-14-banking-adaptive_tool_use\n",
      "gpt-4.1-nano-2025-04-14-banking-adversarial_input_mitigation\n",
      "gpt-4.1-nano-2025-04-14-banking-extreme_scenario_recovery\n",
      "gpt-4.1-nano-2025-04-14-banking-empathetic_resolution\n",
      "gpt-4.1-nano-2025-04-14-banking-scope_management\n",
      "gpt-4.1-nano-2025-04-14-banking-adaptive_tool_use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>average_tool_selection_quality</th>\n",
       "      <th>model</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4.1-mini-2025-04-14-banking-extreme_scenar...</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>extreme_scenario_recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4.1-mini-2025-04-14-banking-empathetic_res...</td>\n",
       "      <td>0.876335</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>empathetic_resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4.1-mini-2025-04-14-banking-scope_management</td>\n",
       "      <td>0.817000</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>scope_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4.1-mini-2025-04-14-banking-adaptive_tool_use</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>adaptive_tool_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14-banking-adversarial_in...</td>\n",
       "      <td>0.853935</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>adversarial_input_mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14-banking-extreme_scenar...</td>\n",
       "      <td>0.574379</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>extreme_scenario_recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14-banking-empathetic_res...</td>\n",
       "      <td>0.678250</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>empathetic_resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14-banking-scope_management</td>\n",
       "      <td>0.742581</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>scope_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14-banking-adaptive_tool_use</td>\n",
       "      <td>0.754834</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>adaptive_tool_use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name  \\\n",
       "0  gpt-4.1-mini-2025-04-14-banking-extreme_scenar...   \n",
       "1  gpt-4.1-mini-2025-04-14-banking-empathetic_res...   \n",
       "2   gpt-4.1-mini-2025-04-14-banking-scope_management   \n",
       "3  gpt-4.1-mini-2025-04-14-banking-adaptive_tool_use   \n",
       "4  gpt-4.1-nano-2025-04-14-banking-adversarial_in...   \n",
       "5  gpt-4.1-nano-2025-04-14-banking-extreme_scenar...   \n",
       "6  gpt-4.1-nano-2025-04-14-banking-empathetic_res...   \n",
       "7   gpt-4.1-nano-2025-04-14-banking-scope_management   \n",
       "8  gpt-4.1-nano-2025-04-14-banking-adaptive_tool_use   \n",
       "\n",
       "   average_tool_selection_quality                    model  \\\n",
       "0                        0.887500  gpt-4.1-mini-2025-04-14   \n",
       "1                        0.876335  gpt-4.1-mini-2025-04-14   \n",
       "2                        0.817000  gpt-4.1-mini-2025-04-14   \n",
       "3                        0.883838  gpt-4.1-mini-2025-04-14   \n",
       "4                        0.853935  gpt-4.1-nano-2025-04-14   \n",
       "5                        0.574379  gpt-4.1-nano-2025-04-14   \n",
       "6                        0.678250  gpt-4.1-nano-2025-04-14   \n",
       "7                        0.742581  gpt-4.1-nano-2025-04-14   \n",
       "8                        0.754834  gpt-4.1-nano-2025-04-14   \n",
       "\n",
       "                       category  \n",
       "0     extreme_scenario_recovery  \n",
       "1         empathetic_resolution  \n",
       "2              scope_management  \n",
       "3             adaptive_tool_use  \n",
       "4  adversarial_input_mitigation  \n",
       "5     extreme_scenario_recovery  \n",
       "6         empathetic_resolution  \n",
       "7              scope_management  \n",
       "8             adaptive_tool_use  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe with the experiment name, average tool selection quality, and average action completion\n",
    "\n",
    "data = []\n",
    "for exp in get_experiments(project_id=project_id):\n",
    "    if exp.name == \"gpt-4.1-mini-2025-04-14-banking-adversarial_input_mitigation\":\n",
    "        continue\n",
    "    print(exp.name)\n",
    "    model, category = exp.name.split(\"-banking-\")\n",
    "    metrics = exp.additional_properties['aggregate_metrics']        \n",
    "    data.append({'experiment_name': exp.name, 'average_tool_selection_quality': metrics['average_tool_selection_quality'], 'model': model, 'category': category})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "gpt-4.1-mini-2025-04-14    0.866168\n",
       "gpt-4.1-nano-2025-04-14    0.720796\n",
       "Name: average_tool_selection_quality, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get avg average_tool_selection_quality group by model and category\n",
    "df.groupby(['model'])['average_tool_selection_quality'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>adaptive_tool_use</th>\n",
       "      <th>adversarial_input_mitigation</th>\n",
       "      <th>empathetic_resolution</th>\n",
       "      <th>extreme_scenario_recovery</th>\n",
       "      <th>scope_management</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4.1-mini-2025-04-14</th>\n",
       "      <td>0.883838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876335</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4.1-nano-2025-04-14</th>\n",
       "      <td>0.754834</td>\n",
       "      <td>0.853935</td>\n",
       "      <td>0.678250</td>\n",
       "      <td>0.574379</td>\n",
       "      <td>0.742581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category                 adaptive_tool_use  adversarial_input_mitigation  \\\n",
       "model                                                                      \n",
       "gpt-4.1-mini-2025-04-14           0.883838                           NaN   \n",
       "gpt-4.1-nano-2025-04-14           0.754834                      0.853935   \n",
       "\n",
       "category                 empathetic_resolution  extreme_scenario_recovery  \\\n",
       "model                                                                       \n",
       "gpt-4.1-mini-2025-04-14               0.876335                   0.887500   \n",
       "gpt-4.1-nano-2025-04-14               0.678250                   0.574379   \n",
       "\n",
       "category                 scope_management  \n",
       "model                                      \n",
       "gpt-4.1-mini-2025-04-14          0.817000  \n",
       "gpt-4.1-nano-2025-04-14          0.742581  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a side by side table where cols are model name\n",
    "df.pivot(index='model', columns='category', values='average_tool_selection_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agentic_session_success_total_cost 0.0\n",
      "agentic_workflow_success_total_cost 0.0\n",
      "average_agentic_session_success 0.41\n",
      "average_agentic_workflow_success 0.9\n",
      "average_tool_selection_quality 0.75\n",
      "tool_selection_quality_total_cost 0.0\n",
      "total_responses 50.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in experiment.additional_properties['aggregate_metrics'].items():\n",
    "    print(k, round(v, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.9\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "metrics = experiment.additional_properties['aggregate_metrics']\n",
    "avg_tool_selection_quality = round(metrics['average_tool_selection_quality'], 2)\n",
    "avg_action_advancement = round(metrics['average_agentic_workflow_success'], 2)\n",
    "avg_action_completion = round(metrics['average_agentic_session_success'], 2)\n",
    "\n",
    "print(avg_tool_selection_quality)\n",
    "print(avg_action_advancement)\n",
    "print(avg_action_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>average_tool_selection_quality</th>\n",
       "      <th>model</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-extreme_scenario_re...</td>\n",
       "      <td>0.860880</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>extreme_scenario_recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-empathetic_resolution</td>\n",
       "      <td>0.923514</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>empathetic_resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-adaptive_tool_use</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>adaptive_tool_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-scope_management</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>scope_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-adversarial_input_m...</td>\n",
       "      <td>0.941288</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>adversarial_input_mitigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name  \\\n",
       "0  gpt-4.1-2025-04-14-banking-extreme_scenario_re...   \n",
       "1   gpt-4.1-2025-04-14-banking-empathetic_resolution   \n",
       "2       gpt-4.1-2025-04-14-banking-adaptive_tool_use   \n",
       "3        gpt-4.1-2025-04-14-banking-scope_management   \n",
       "4  gpt-4.1-2025-04-14-banking-adversarial_input_m...   \n",
       "\n",
       "   average_tool_selection_quality               model  \\\n",
       "0                        0.860880  gpt-4.1-2025-04-14   \n",
       "1                        0.923514  gpt-4.1-2025-04-14   \n",
       "2                        0.923611  gpt-4.1-2025-04-14   \n",
       "3                        0.858333  gpt-4.1-2025-04-14   \n",
       "4                        0.941288  gpt-4.1-2025-04-14   \n",
       "\n",
       "                       category  \n",
       "0     extreme_scenario_recovery  \n",
       "1         empathetic_resolution  \n",
       "2             adaptive_tool_use  \n",
       "3              scope_management  \n",
       "4  adversarial_input_mitigation  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = \"gpt-4.1-2025-04-14\"\n",
    "project_id = get_project(name=project_name).id\n",
    "\n",
    "data = []\n",
    "for exp in get_experiments(project_id=project_id):\n",
    "    model, category = exp.name.split(\"-banking-\")\n",
    "    metrics = exp.additional_properties['aggregate_metrics']        \n",
    "    data.append({'experiment_name': exp.name, 'average_tool_selection_quality': metrics['average_tool_selection_quality'], 'model': model, 'category': category})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8608796335756779,\n",
       " 0.9235139882022684,\n",
       " 0.9236111132936045,\n",
       " 0.8583333373069764,\n",
       " 0.9412878792394291]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.average_tool_selection_quality.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8915845180946318)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean([0.8608796335756779,\n",
    " 0.9235139882022684,\n",
    " 0.9236111132936045,\n",
    " 0.8583333373069764])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agentic_session_success_total_cost': 3.4152399972081184, 'average_agentic_session_success': 0.9733333343267441, 'average_cost': 1.4000000000000001e-05, 'average_tool_selection_quality': 0.8723477643728256, 'tool_selection_quality_total_cost': 0.0, 'total_cost': 0.0063560000000000005, 'total_responses': 50.0, 'total_metrics_cost': 3.4152399972081184}\n",
      "{'agentic_session_success_total_cost': 3.3799539878964424, 'average_agentic_session_success': 0.9666666674613953, 'average_cost': 1.4e-05, 'average_tool_selection_quality': 0.917913922071457, 'tool_selection_quality_total_cost': 0.0, 'total_cost': 0.0056, 'total_responses': 50.0, 'total_metrics_cost': 3.3799539878964424}\n",
      "{'agentic_session_success_total_cost': 3.1796519942581654, 'average_agentic_session_success': 1.0, 'average_cost': 1.4e-05, 'average_tool_selection_quality': 0.9171428596973419, 'tool_selection_quality_total_cost': 0.0, 'total_cost': 0.004312, 'total_responses': 50.0, 'total_metrics_cost': 3.1796519942581654}\n",
      "{'agentic_session_success_total_cost': 2.540256004780531, 'average_agentic_session_success': 0.8533333349227905, 'average_cost': 1.4e-05, 'average_tool_selection_quality': 0.7896190524101258, 'tool_selection_quality_total_cost': 0.0, 'total_cost': 0.004032, 'total_responses': 50.0, 'total_metrics_cost': 2.540256004780531}\n",
      "{'agentic_session_success_total_cost': 1.9983560033142567, 'average_agentic_session_success': 0.7666666704416275, 'average_cost': 1.4e-05, 'average_tool_selection_quality': 0.9454285728931427, 'tool_selection_quality_total_cost': 0.0, 'total_cost': 0.00462, 'total_responses': 50.0, 'total_metrics_cost': 1.9983560033142567}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>average_tool_selection_quality</th>\n",
       "      <th>average_agentic_session_success</th>\n",
       "      <th>model</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-extreme_scenario_re...</td>\n",
       "      <td>0.872348</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>extreme_scenario_recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-empathetic_resolution</td>\n",
       "      <td>0.917914</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>empathetic_resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-adaptive_tool_use</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>adaptive_tool_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-scope_management</td>\n",
       "      <td>0.789619</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>scope_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4.1-2025-04-14-banking-adversarial_input_m...</td>\n",
       "      <td>0.945429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>adversarial_input_mitigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name  \\\n",
       "0  gpt-4.1-2025-04-14-banking-extreme_scenario_re...   \n",
       "1   gpt-4.1-2025-04-14-banking-empathetic_resolution   \n",
       "2       gpt-4.1-2025-04-14-banking-adaptive_tool_use   \n",
       "3        gpt-4.1-2025-04-14-banking-scope_management   \n",
       "4  gpt-4.1-2025-04-14-banking-adversarial_input_m...   \n",
       "\n",
       "   average_tool_selection_quality  average_agentic_session_success  \\\n",
       "0                        0.872348                         0.973333   \n",
       "1                        0.917914                         0.966667   \n",
       "2                        0.917143                         1.000000   \n",
       "3                        0.789619                         0.853333   \n",
       "4                        0.945429                         0.766667   \n",
       "\n",
       "                model                      category  \n",
       "0  gpt-4.1-2025-04-14     extreme_scenario_recovery  \n",
       "1  gpt-4.1-2025-04-14         empathetic_resolution  \n",
       "2  gpt-4.1-2025-04-14             adaptive_tool_use  \n",
       "3  gpt-4.1-2025-04-14              scope_management  \n",
       "4  gpt-4.1-2025-04-14  adversarial_input_mitigation  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = \"gpt-4.1-2025-04-14-with-4.1-mini-simulator\"\n",
    "project_id = get_project(name=project_name).id\n",
    "\n",
    "data = []\n",
    "for exp in get_experiments(project_id=project_id):\n",
    "    model, category = exp.name.split(\"-banking-\")\n",
    "    metrics = exp.additional_properties['aggregate_metrics']   \n",
    "    print(metrics)\n",
    "    data.append({'experiment_name': exp.name, 'average_tool_selection_quality': metrics['average_tool_selection_quality'], 'average_agentic_session_success': metrics['average_agentic_session_success'], 'model': model, 'category': category})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
